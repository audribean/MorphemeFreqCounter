{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have two datasets: [English morphemes](https://colingoldberg.github.io/morphemes/morpheme/dataset/2019/06/03/morpheme-dataset.html) and their characteristics derived from WordNet and [frequency counts](https://www.kaggle.com/datasets/rtatman/english-word-frequency) of English words from the Google Web Trillion Word Corpus. Here I aim to create a morpheme dataset that incorporates the cumulative frequencies of words in which each morpheme occurs. I got far enough to accumulate the frequencies of most morphemes, but I fail to account for allomorphy or affixes that do not appear at the immediate starts and ends of words. I ended up finding a dataset with exactly what I was trying to create, but I would still like to figure out how to fully implement this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming JSON of morphemes to Pandas df\n",
    "with open(\"data/morphemes.json\") as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "df_list = []\n",
    "\n",
    "'''\n",
    "A different method I considered: the JSON data contains examples of words the morphemes can belong to, and I could look up the\n",
    "frequencies of those words in the other dataset, but that list is not exhaustive.\n",
    "'''\n",
    "\n",
    "# Removed meaning, etymology, examples, categories\n",
    "for key, value in json_data.items():\n",
    "    forms_data = value.get('forms', [{}])[0]\n",
    "    entry = {\n",
    "        'Affix': forms_data.get('form', ''),\n",
    "        'Type': forms_data.get('loc', ''),\n",
    "        #'Form_Type': forms_data.get('type', ''), # Too may NaN values\n",
    "        'Origin': value.get('origin', '')\n",
    "    }\n",
    "    df_list.append(entry)\n",
    "\n",
    "df = pd.DataFrame(df_list)\n",
    "\n",
    "# Removed non-affixes\n",
    "df = df[df['Type'] != 'embedded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Affix    Type Origin\n",
      "count   2374    2374   2374\n",
      "unique  2325       2     24\n",
      "top       en  prefix  Latin\n",
      "freq       4    1998    857\n"
     ]
    }
   ],
   "source": [
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Greek', 'Latin, Greek', 'Latin', 'French', 'throw',\n",
       "       'Latin from Greek', 'Latin and Greek', 'Irish', 'German',\n",
       "       'G. entoma', 'L. flagrum', 'L.gene', 'Greek, Latin', 'Latin Greek',\n",
       "       'Italian', 'G. merus', 'G. meion', 'nectere, nexus',\n",
       "       'Middle English', 'English', 'greek', 'Greek from Hebrew',\n",
       "       'Greek '], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Origin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the origin column\n",
    "origin_mapping = {\n",
    "    '': 'Unspecified',\n",
    "    'Latin from Greek': 'Latin, Greek',\n",
    "    'Greek, Latin': 'Latin, Greek',\n",
    "    'Latin Greek': 'Latin, Greek',\n",
    "    '\"Latin, Greek\"': 'Latin, Greek',\n",
    "    'Latin and Greek': 'Latin, Greek',\n",
    "    'Greek ': 'Greek',\n",
    "    'greek': 'Greek',\n",
    "    'G. entoma': 'Greek',\n",
    "    'G. merus': 'Greek',\n",
    "    'G. meion': 'Greek',\n",
    "    'nectere, nexus': 'Latin',\n",
    "    'L. flagrum': 'Latin',\n",
    "    'L.gene': 'Latin',\n",
    "    'Greek from Hebrew': 'Greek, Hebrew'\n",
    "}\n",
    "\n",
    "# Applying the new mapping\n",
    "df['Origin'] = df['Origin'].replace(origin_mapping)\n",
    "\n",
    "# Remove throw\n",
    "df = df[df['Origin'] != 'throw']\n",
    "\n",
    "# Also make all affixes lowercase\n",
    "df['Affix'] = df['Affix'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Affix</th>\n",
       "      <th>Type</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afro</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anglo</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>euro</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>franco</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indo</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hell</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abac</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abil</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>able</td>\n",
       "      <td>suffix</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ably</td>\n",
       "      <td>suffix</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>abol</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>academ</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>acantho</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>acaro</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>aceae</td>\n",
       "      <td>suffix</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Affix    Type       Origin\n",
       "0      afro  prefix  Unspecified\n",
       "1     anglo  prefix  Unspecified\n",
       "2      euro  prefix  Unspecified\n",
       "3    franco  prefix  Unspecified\n",
       "4      indo  prefix  Unspecified\n",
       "5      hell  prefix        Greek\n",
       "6      abac  prefix        Greek\n",
       "7      abil  prefix  Unspecified\n",
       "8      able  suffix  Unspecified\n",
       "9      ably  suffix  Unspecified\n",
       "10     abol  prefix  Unspecified\n",
       "11   academ  prefix        Greek\n",
       "12  acantho  prefix        Greek\n",
       "13    acaro  prefix        Greek\n",
       "14    aceae  suffix  Unspecified"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The new dataset\n",
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>23135851162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>13151942776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and</td>\n",
       "      <td>12997637966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>12136980858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>9081174698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  word        count\n",
       "0  the  23135851162\n",
       "1   of  13151942776\n",
       "2  and  12997637966\n",
       "3   to  12136980858\n",
       "4    a   9081174698"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the frequency dataset\n",
    "freq = pd.read_csv('data/unigram_freq.csv')\n",
    "freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates:\n",
      " 12819    NaN\n",
      "Name: word, dtype: object\n",
      "Missing Values:\n",
      " 2577     NaN\n",
      "12819    NaN\n",
      "Name: word, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicated values in 'word' column\n",
    "duplicated_words = freq[freq.duplicated('word')]['word']\n",
    "print(f'Duplicates:\\n {duplicated_words}')\n",
    "\n",
    "# Check for missing values in 'word' column\n",
    "missing_words = freq[freq['word'].isnull()]['word']\n",
    "print(f'Missing Values:\\n {missing_words}')\n",
    "\n",
    "# Drop those instances\n",
    "freq = freq.drop_duplicates('word')\n",
    "freq = freq.dropna(subset=['word'])\n",
    "\n",
    "#Make all words lowercase\n",
    "freq['word'] = freq['word'].str.lower()\n",
    "\n",
    "#freq.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my first attempt:\n",
    "\n",
    "I take each affix and see if it appears at the starts or ends (according to whether it is a prefix or suffix) of words. I then accumulate the frequencies of those words and append this number to the morpheme dataset. This is problematic, because affixes can appear in the middle of words, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2420, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Affix</th>\n",
       "      <th>Type_x</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Type_y</th>\n",
       "      <th>TotalFrequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afro</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>prefix</td>\n",
       "      <td>2647152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anglo</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>prefix</td>\n",
       "      <td>3591523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>euro</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>prefix</td>\n",
       "      <td>225990569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>franco</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>prefix</td>\n",
       "      <td>6772175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indo</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>prefix</td>\n",
       "      <td>44708427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Affix  Type_x       Origin  Type_y  TotalFrequency\n",
       "0    afro  prefix  Unspecified  prefix         2647152\n",
       "1   anglo  prefix  Unspecified  prefix         3591523\n",
       "2    euro  prefix  Unspecified  prefix       225990569\n",
       "3  franco  prefix  Unspecified  prefix         6772175\n",
       "4    indo  prefix  Unspecified  prefix        44708427"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the unique affixes\n",
    "unique_affixes_in_df = df[['Affix', 'Type']].drop_duplicates()\n",
    "\n",
    "results = []\n",
    "\n",
    "for _, row in unique_affixes_in_df.iterrows():\n",
    "    affix = row['Affix']\n",
    "    affix_type = row['Type']\n",
    "\n",
    "    # Regex: Prefixes at the start of words, suffixes at the end\n",
    "    pattern = f'^{affix}' if affix_type == 'prefix' else f'{affix}$'\n",
    "\n",
    "    # Get words with this pattern\n",
    "    contains_affix = freq['word'].str.contains(pattern, regex=True)\n",
    "    words_with_affix_df = freq[contains_affix]\n",
    "\n",
    "    # Accumulate frequencies\n",
    "    total_frequency = words_with_affix_df['count'].sum()\n",
    "    result_entry = {'Affix': affix, 'Type': affix_type, 'TotalFrequency': total_frequency}\n",
    "\n",
    "    results.append(result_entry)\n",
    "\n",
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "# Appending the value and cleaning the new dataframe\n",
    "merged_df = pd.merge(df, result_df, on='Affix', how='left')\n",
    "merged_df['TotalFrequency'].fillna(0, inplace=True)\n",
    "merged_df['TotalFrequency'] = merged_df['TotalFrequency'].astype(int)\n",
    "\n",
    "print(merged_df.shape)\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an alternative to regex, and it might be faster?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif affix_type == \\'prefix\\':\\n        contains_affix = freq[\\'word\\'].str.startswith(affix)\\n    elif affix_type == \\'suffix\\':\\n        contains_affix = freq[\\'word\\'].str.endswith(affix)\\n    else:\\n        print(f\"Unsupported affix type: {affix_type}\")\\n        continue\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "if affix_type == 'prefix':\n",
    "        contains_affix = freq['word'].str.startswith(affix)\n",
    "    elif affix_type == 'suffix':\n",
    "        contains_affix = freq['word'].str.endswith(affix)\n",
    "    else:\n",
    "        print(f\"Unsupported affix type: {affix_type}\")\n",
    "        continue\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my second attempt, where my first method becomes iterative; after finding an affix, I remove it and keep checking to see if it contains more affixes. For example, \"incarcerated\" -> \"incarcerate\" -> \"carcerate\" -> \"ate\". The problem with this method is that it is computationally expensive and also does not account for allomorphy, or when morphemes might change slightly depending on its context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/audri/Desktop/Project/preprocess.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/audri/Desktop/Project/preprocess.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mwhile\u001b[39;00m contains_affix\u001b[39m.\u001b[39many():\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/audri/Desktop/Project/preprocess.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# Remove the first instance of the affix from each word\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/audri/Desktop/Project/preprocess.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     freq[\u001b[39m'\u001b[39m\u001b[39mword\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m freq[\u001b[39m'\u001b[39m\u001b[39mword\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mreplace(pattern, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, n\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/audri/Desktop/Project/preprocess.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     contains_affix \u001b[39m=\u001b[39m freq[\u001b[39m'\u001b[39;49m\u001b[39mword\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49mcontains(pattern, regex\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/audri/Desktop/Project/preprocess.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39m# Accumulate freq of next found affix?\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/audri/Desktop/Project/preprocess.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m# ...\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/audri/Desktop/Project/preprocess.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/audri/Desktop/Project/preprocess.ipynb#X13sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# the rest is also the same\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/audri/Desktop/Project/preprocess.ipynb#X13sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m total_frequency \u001b[39m=\u001b[39m words_with_affix_df[\u001b[39m'\u001b[39m\u001b[39mcount\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msum()\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/core/strings/accessor.py:136\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    132\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot use .str.\u001b[39m\u001b[39m{\u001b[39;00mfunc_name\u001b[39m}\u001b[39;00m\u001b[39m with values of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minferred dtype \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inferred_dtype\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m     )\n\u001b[1;32m    135\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 136\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/core/strings/accessor.py:1310\u001b[0m, in \u001b[0;36mStringMethods.contains\u001b[0;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[39mif\u001b[39;00m regex \u001b[39mand\u001b[39;00m re\u001b[39m.\u001b[39mcompile(pat)\u001b[39m.\u001b[39mgroups:\n\u001b[1;32m   1303\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1304\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis pattern is interpreted as a regular expression, and has \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1305\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmatch groups. To actually get the groups, use str.extract.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1306\u001b[0m         \u001b[39mUserWarning\u001b[39;00m,\n\u001b[1;32m   1307\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1308\u001b[0m     )\n\u001b[0;32m-> 1310\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data\u001b[39m.\u001b[39;49marray\u001b[39m.\u001b[39;49m_str_contains(pat, case, flags, na, regex)\n\u001b[1;32m   1311\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap_result(result, fill_value\u001b[39m=\u001b[39mna, returns_string\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/core/strings/object_array.py:145\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_contains\u001b[0;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[1;32m    143\u001b[0m         upper_pat \u001b[39m=\u001b[39m pat\u001b[39m.\u001b[39mupper()\n\u001b[1;32m    144\u001b[0m         f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: upper_pat \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mupper()\n\u001b[0;32m--> 145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_str_map(f, na, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mdtype(\u001b[39m\"\u001b[39;49m\u001b[39mbool\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/core/strings/object_array.py:78\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_map\u001b[0;34m(self, f, na_value, dtype, convert)\u001b[0m\n\u001b[1;32m     76\u001b[0m map_convert \u001b[39m=\u001b[39m convert \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(mask)\n\u001b[1;32m     77\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     result \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer_mask(arr, f, mask\u001b[39m.\u001b[39;49mview(np\u001b[39m.\u001b[39;49muint8), map_convert)\n\u001b[1;32m     79\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mAttributeError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m     80\u001b[0m     \u001b[39m# Reraise the exception if callable `f` got wrong number of args.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[39m# The user may want to be warned by this, instead of getting NaN\u001b[39;00m\n\u001b[1;32m     82\u001b[0m     p_err \u001b[39m=\u001b[39m (\n\u001b[1;32m     83\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m((takes)|(missing)) (?(2)from \u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+ to )?\u001b[39m\u001b[39m\\\u001b[39m\u001b[39md+ \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     84\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(?(3)required )positional arguments?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     85\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2872\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/cpsc330/lib/python3.10/site-packages/pandas/core/strings/object_array.py:138\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_contains.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    134\u001b[0m         flags \u001b[39m|\u001b[39m\u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mIGNORECASE\n\u001b[1;32m    136\u001b[0m     pat \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39mcompile(pat, flags\u001b[39m=\u001b[39mflags)\n\u001b[0;32m--> 138\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m x: pat\u001b[39m.\u001b[39;49msearch(x) \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[39mif\u001b[39;00m case:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This is the same as before\n",
    "unique_affixes_in_df = df[['Affix', 'Type']].drop_duplicates()\n",
    "\n",
    "results = []\n",
    "\n",
    "for _, row in unique_affixes_in_df.iterrows():\n",
    "    affix = row['Affix']\n",
    "    affix_type = row['Type']\n",
    "\n",
    "    pattern = f'.*?{affix}' if affix_type == 'prefix' else f'{affix}.*?'\n",
    "    contains_affix = freq['word'].str.contains(pattern, regex=True)\n",
    "    words_with_affix_df = freq[contains_affix]\n",
    "\n",
    "    # Here is the change:\n",
    "    # While the word has an affix, count its frequency, remove the affix, see if it still has an affix\n",
    "    while contains_affix.any():\n",
    "        # Remove the first instance of the affix from each word\n",
    "        freq['word'] = freq['word'].str.replace(pattern, '', n=1)\n",
    "        contains_affix = freq['word'].str.contains(pattern, regex=True)\n",
    "        # Accumulate freq of next found affix?\n",
    "        # ...\n",
    "\n",
    "    # the rest is also the same\n",
    "    total_frequency = words_with_affix_df['count'].sum()\n",
    "    result_entry = {'Affix': affix, 'Type': affix_type, 'TotalFrequency': total_frequency}\n",
    "\n",
    "    results.append(result_entry)\n",
    "\n",
    "result_df = pd.DataFrame(results)\n",
    "\n",
    "merged_df = pd.merge(df, result_df, on='Affix', how='left')\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting to csv\n",
    "merged_df.to_csv(\"data/affixes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Affix</th>\n",
       "      <th>Type_x</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Type_y</th>\n",
       "      <th>TotalFrequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ailur</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Greek</td>\n",
       "      <td>prefix</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>alphit</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Greek</td>\n",
       "      <td>prefix</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>camisi</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Latin</td>\n",
       "      <td>prefix</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>carcer</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Latin</td>\n",
       "      <td>prefix</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>centesim</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Latin</td>\n",
       "      <td>prefix</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>trit-</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Greek</td>\n",
       "      <td>prefix</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2253</th>\n",
       "      <td>tymb</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Greek</td>\n",
       "      <td>prefix</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2265</th>\n",
       "      <td>uligin</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Latin</td>\n",
       "      <td>prefix</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>xera</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Greek</td>\n",
       "      <td>prefix</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>zizyph</td>\n",
       "      <td>prefix</td>\n",
       "      <td>Greek</td>\n",
       "      <td>prefix</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Affix  Type_x Origin  Type_y  TotalFrequency\n",
       "50       ailur  prefix  Greek  prefix               0\n",
       "65      alphit  prefix  Greek  prefix               0\n",
       "282     camisi  prefix  Latin  prefix               0\n",
       "297     carcer  prefix  Latin  prefix               0\n",
       "334   centesim  prefix  Latin  prefix               0\n",
       "...        ...     ...    ...     ...             ...\n",
       "2233    trit-   prefix  Greek  prefix               0\n",
       "2253      tymb  prefix  Greek  prefix               0\n",
       "2265    uligin  prefix  Latin  prefix               0\n",
       "2401      xera  prefix  Greek  prefix               0\n",
       "2414    zizyph  prefix  Greek  prefix               0\n",
       "\n",
       "[135 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many affixes were not counted:\n",
    "merged_df[merged_df['TotalFrequency'] == 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc330",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
